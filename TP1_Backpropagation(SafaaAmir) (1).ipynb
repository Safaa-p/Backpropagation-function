{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "0anqEBVGccy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fonction d'activation sigmoïde et sa dérivée"
      ],
      "metadata": {
        "id": "_rFovC4ocVMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)"
      ],
      "metadata": {
        "id": "4wcGPnIgcUdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialisation des poids"
      ],
      "metadata": {
        "id": "ubFF_IuqcoiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(input_size, hidden1_size, hidden2_size, output_size):\n",
        "    np.random.seed(42)\n",
        "    weights_input_hidden1 = np.random.rand(input_size, hidden1_size)\n",
        "    weights_hidden1_hidden2 = np.random.rand(hidden1_size, hidden2_size)\n",
        "    weights_hidden2_output = np.random.rand(hidden2_size, output_size)\n",
        "    bias_hidden1 = np.zeros((1, hidden1_size))\n",
        "    bias_hidden2 = np.zeros((1, hidden2_size))\n",
        "    bias_output = np.zeros((1, output_size))\n",
        "\n",
        "    return weights_input_hidden1, weights_hidden1_hidden2, weights_hidden2_output, bias_hidden1, bias_hidden2, bias_output"
      ],
      "metadata": {
        "id": "bw3PyPWYcrO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Propagation avant"
      ],
      "metadata": {
        "id": "fG7q6FIQdi7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(inputs, weights_input_hidden1, weights_hidden1_hidden2, weights_hidden2_output, bias_hidden1, bias_hidden2, bias_output):\n",
        "    layer1_output = sigmoid(np.dot(inputs, weights_input_hidden1) + bias_hidden1)\n",
        "    layer2_output = sigmoid(np.dot(layer1_output, weights_hidden1_hidden2) + bias_hidden2)\n",
        "    output = sigmoid(np.dot(layer2_output, weights_hidden2_output) + bias_output)\n",
        "\n",
        "    return layer1_output, layer2_output, output\n"
      ],
      "metadata": {
        "id": "sLOkiaXzdk8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rétropropagation"
      ],
      "metadata": {
        "id": "S23-eOMbd3et"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_propagation(inputs, targets, layer1_output, layer2_output, output, weights_input_hidden1, weights_hidden1_hidden2, weights_hidden2_output, bias_hidden1, bias_hidden2, bias_output, learning_rate):\n",
        "    output_error = targets - output\n",
        "    output_delta = output_error * sigmoid_derivative(output)\n",
        "\n",
        "    layer2_error = output_delta.dot(weights_hidden2_output.T)\n",
        "    layer2_delta = layer2_error * sigmoid_derivative(layer2_output)\n",
        "\n",
        "    layer1_error = layer2_delta.dot(weights_hidden1_hidden2.T)\n",
        "    layer1_delta = layer1_error * sigmoid_derivative(layer1_output)\n",
        "\n",
        "    weights_hidden2_output += layer2_output.T.dot(output_delta) * learning_rate\n",
        "    weights_hidden1_hidden2 += layer1_output.T.dot(layer2_delta) * learning_rate\n",
        "    weights_input_hidden1 += inputs.T.dot(layer1_delta) * learning_rate\n",
        "\n",
        "    bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
        "    bias_hidden2 += np.sum(layer2_delta, axis=0, keepdims=True) * learning_rate\n",
        "    bias_hidden1 += np.sum(layer1_delta, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    return weights_input_hidden1, weights_hidden1_hidden2, weights_hidden2_output, bias_hidden1, bias_hidden2, bias_output"
      ],
      "metadata": {
        "id": "p_ahYYnyd9yM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entraınement du réseau"
      ],
      "metadata": {
        "id": "UmCFNC7seM2L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPnnyYkRcPY8",
        "outputId": "cc4a4e37-15ed-4d73-d2bf-2df7c0d38509"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prédictions finales :\n",
            "[[0.07722725]\n",
            " [0.6730405 ]\n",
            " [0.64631677]\n",
            " [0.61428293]]\n"
          ]
        }
      ],
      "source": [
        "def train_neural_network(inputs, targets, hidden1_size, hidden2_size, output_size, epochs, learning_rate):\n",
        "    input_size = inputs.shape[1]\n",
        "\n",
        "    weights_input_hidden1, weights_hidden1_hidden2, weights_hidden2_output, bias_hidden1, bias_hidden2, bias_output = initialize_weights(input_size, hidden1_size, hidden2_size, output_size)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        layer1_output, layer2_output, network_output = forward_propagation(inputs, weights_input_hidden1, weights_hidden1_hidden2, weights_hidden2_output, bias_hidden1, bias_hidden2, bias_output)\n",
        "        weights_input_hidden1, weights_hidden1_hidden2, weights_hidden2_output, bias_hidden1, bias_hidden2, bias_output = backward_propagation(inputs, targets, layer1_output, layer2_output, network_output, weights_input_hidden1, weights_hidden1_hidden2, weights_hidden2_output, bias_hidden1, bias_hidden2, bias_output, learning_rate)\n",
        "\n",
        "    return weights_input_hidden1, weights_hidden1_hidden2, weights_hidden2_output, bias_hidden1, bias_hidden2, bias_output\n",
        "\n",
        "# Exemple d'utilisation avec des données d'entraînement fictives\n",
        "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "targets = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "trained_weights = train_neural_network(inputs, targets, hidden1_size=4, hidden2_size=3, output_size=1, epochs=10000, learning_rate=0.1)\n",
        "\n",
        "# Utilisez les poids entraînés pour faire des prédictions\n",
        "_, _, predictions = forward_propagation(inputs, *trained_weights)\n",
        "print(\"Prédictions finales :\")\n",
        "print(predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exercice2**"
      ],
      "metadata": {
        "id": "MsJr1hvZ_iza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial weights and biases\n",
        "w1 = np.array([[0.15, 0.25], [0.20, 0.30]])\n",
        "b1 = np.array([0.35, 0.35])\n",
        "w2 = np.array([[0.40], [0.45]])\n",
        "b2 = np.array([0.60])\n",
        "\n",
        "# Inputs\n",
        "x = np.array([0.05, 0.10])\n",
        "\n",
        "# Expected output\n",
        "y_true = 0.01\n",
        "\n",
        "# Learning rate\n",
        "learning_rate = 0.1\n"
      ],
      "metadata": {
        "id": "4Ps9mh1O_lMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forward propagation"
      ],
      "metadata": {
        "id": "fPSyHx2C_vmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input to hidden layer\n",
        "z1 = np.dot(x, w1) + b1\n",
        "a1 = sigmoid(z1)\n",
        "\n",
        "# Hidden to output layer\n",
        "z2 = np.dot(a1, w2) + b2\n",
        "y_pred = sigmoid(z2)\n"
      ],
      "metadata": {
        "id": "aFAtGkOE_trF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Mean Squared Error (MSE):"
      ],
      "metadata": {
        "id": "RZtODYHk_2f9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse = 0.5 * ((y_true - y_pred) ** 2)"
      ],
      "metadata": {
        "id": "AWx19KWv_znI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backward Propagation:"
      ],
      "metadata": {
        "id": "dWYDHJF9_7z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Output layer\n",
        "delta2 = (y_pred - y_true) * sigmoid_derivative(y_pred)\n",
        "dw2 = np.outer(a1, delta2)\n",
        "db2 = delta2\n",
        "\n",
        "# Hidden layer\n",
        "delta1 = np.dot(delta2, w2.T) * sigmoid_derivative(a1)\n",
        "dw1 = np.outer(x, delta1)\n",
        "db1 = delta1\n"
      ],
      "metadata": {
        "id": "Pi07eXiw_54F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Update Weights and Biases:"
      ],
      "metadata": {
        "id": "hHxo1cyfABli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w2 -= learning_rate * dw2\n",
        "b2 -= learning_rate * db2\n",
        "\n",
        "w1 -= learning_rate * dw1\n",
        "b1 -= learning_rate * db1\n"
      ],
      "metadata": {
        "id": "x7j_aiHV__3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print results\n",
        "print(\"Forward Propagation:\")\n",
        "print(f\"z1: {z1}\")\n",
        "print(f\"a1: {a1}\")\n",
        "print(f\"z2: {z2}\")\n",
        "print(f\"y_pred: {y_pred}\")\n",
        "\n",
        "print(\"\\nMean Squared Error (MSE):\")\n",
        "print(f\"MSE: {mse}\")\n",
        "\n",
        "print(\"\\nBackward Propagation:\")\n",
        "print(f\"delta2: {delta2}\")\n",
        "print(f\"dw2: {dw2}\")\n",
        "print(f\"db2: {db2}\")\n",
        "print(f\"delta1: {delta1}\")\n",
        "print(f\"dw1: {dw1}\")\n",
        "print(f\"db1: {db1}\")\n",
        "\n",
        "print(\"\\nUpdated Weights and Biases:\")\n",
        "print(f\"w1: {w1}\")\n",
        "print(f\"b1: {b1}\")\n",
        "print(f\"w2: {w2}\")\n",
        "print(f\"b2: {b2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_J8F9RdAMPF",
        "outputId": "a70642ef-7fc5-40ed-a27c-0eeb16d102cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forward Propagation:\n",
            "z1: [0.3775 0.3925]\n",
            "a1: [0.59326999 0.59688438]\n",
            "z2: [1.10590597]\n",
            "y_pred: [0.75136507]\n",
            "\n",
            "Mean Squared Error (MSE):\n",
            "MSE: [0.27481108]\n",
            "\n",
            "Backward Propagation:\n",
            "delta2: [0.13849856]\n",
            "dw2: [[0.08216704]\n",
            " [0.08266763]]\n",
            "db2: [0.13849856]\n",
            "delta1: [0.01336792 0.01499608]\n",
            "dw1: [[0.0006684  0.0007498 ]\n",
            " [0.00133679 0.00149961]]\n",
            "db1: [0.01336792 0.01499608]\n",
            "\n",
            "Updated Weights and Biases:\n",
            "w1: [[0.14993316 0.24992502]\n",
            " [0.19986632 0.29985004]]\n",
            "b1: [0.34866321 0.34850039]\n",
            "w2: [[0.3917833 ]\n",
            " [0.44173324]]\n",
            "b2: [0.58615014]\n"
          ]
        }
      ]
    }
  ]
}